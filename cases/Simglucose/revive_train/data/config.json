{
    "base_config": [
        {
            "name": "train_venv_trials",
            "abbreviation": "tvt",
            "description": "Number of total trails searched by the search algorithm in venv training.",
            "type": "int",
            "default": 150,
            "doc": true
        },
        {
            "name": "global_seed",
            "abbreviation": "gs",
            "description": "Set the random number seed for the experiment.",
            "type": "int",
            "default": 42
        },
        {
            "name": "val_split_ratio",
            "abbreviation": "vsr",
            "description": "Ratio to split validate dataset if it is not explicitly given.",
            "type": "float",
            "default": 0.5
        },
        {
            "name": "val_split_mode",
            "abbreviation": "vsm",
            "description": "Mode of auto splitting training and validation dataset, choose from `outside_traj` and `inside_traj`. `outside_traj` means the split is happened outside the trajectories, one trajectory can only be in one dataset. `inside_traj` means the split is happened inside the trajectories, former part of one trajectory is in training set, later part is in validation set.",
            "type": "str",
            "default": "outside_traj"
        },
        {
            "name": "ignore_check",
            "abbreviation": "igc",
            "description": "Flag to ignore data related check, force training.",
            "type": "bool",
            "default": false
        },
        {
            "name": "venv_gpus_per_worker",
            "abbreviation": "vgpw",
            "description": "Number of gpus per worker in venv training, small than 1 means launch multiple workers on the same gpu.",
            "type": "float",
            "default": 0.2
        },
        {
            "name": "venv_metric",
            "description": "Metric used to evaluate the trained venv, choose from `nll`, `mae`, `mse`, `wdist`.",
            "type": "str",
            "default": "mae"
        },
        {
            "name": "policy_gpus_per_worker",
            "abbreviation": "pgpw",
            "description": "Number of gpus per worker in venv training, small than 1 means launch multiple workers on the same gpu.",
            "type": "float",
            "default": 0.25
        },
        {
            "name": "save_start_epoch",
            "abbreviation": "sse",
            "description": "We only save models after this epoch, default is 0 which means we save models from the beginning.",
            "type": "int",
            "default": 0
        },
        {
            "name": "venv_train_dataset_mode",
            "abbreviation": "vtdm",
            "description": "Can be set to `trajectory` mode or `transition` mode.",
            "type": "str",
            "default": "trajectory",
            "doc": true
        }
    ],
    "venv_algo_config": {
        "revive_f": [
            {
                "name": "bc_epoch",
                "type": "int",
                "default": 1500
            },
            {
                "name": "mail_epoch",
                "description": "Number of epcoh for the training process",
                "abbreviation": "mep",
                "type": "int",
                "default": 1500
            },
            {
                "name": "bc_lr",
                "type": "float",
                "default": 1e-3
            },
            {
                "name": "bc_steps",
                "type": "int",
                "default": 1
            },
            {
                "name": "matcher_record_len",
                "type": "int",
                "default": 50
            },
            {
                "name": "fix_std",
                "type": "float",
                "default": 0.025
            },
            {
                "name": "bc_l2_coef",
                "type": "float",
                "default": 5e-5
            },
            {
                "name": "logvar_loss_coef",
                "type": "float",
                "default": 0.01
            },
            {
                "name": "matcher_l2_norm_coeff",
                "type": "float",
                "default": 0.0005
            },
            {
                "name": "discr_ent_coef",
                "type": "float",
                "default": 0.01
            },
            {
                "name": "value_l2_norm_coef",
                "type": "float",
                "default": 1e-6
            },
            {
                "name": "generator_l2_norm_coef",
                "type": "float",
                "default": 1e-6
            },
            {
                "name": "gp_coef",
                "type": "float",
                "default": 0.5
            },
            {
                "name": "mix_sample_ratio",
                "type": "float",
                "default": 0.5
            },
            {
                "name": "mix_sample",
                "type": "bool",
                "default": true
            },
            {
                "name": "revive_batch_size",
                "description": "Batch size of training process.",
                "abbreviation": "mbs",
                "type": "int",
                "default": 1024
            },
            {
                "name": "matching_nodes",
                "type": "list",
                "default": [["obs", "action"], ["obs", "action", "next_obs"], ["obs", "action", "delta_x"]]
            },
            {
                "name": "matching_fit_nodes",
                "type": "list",
                "default": [["action"], ["next_obs"], ["delta_x"]]
            },
            {
                "name": "policy_hidden_features",
                "description": "Number of neurons per layer of the policy network.",
                "abbreviation": "phf",
                "type": "int",
                "default": 256
            },
            {
                "name": "policy_hidden_layers",
                "description": "Depth of policy network.",
                "abbreviation": "phl",
                "type": "int",
                "default": 3
            },
            {
                "name": "policy_backbone",
                "description": "Backbone of policy network.",
                "abbreviation": "pb",
                "type": "str",
                "default": "mlp"
            },
            {
                "name": "transition_hidden_features",
                "description": "Number of neurons per layer of the transition network.",
                "abbreviation": "thf",
                "type": "int",
                "default": 256
            },
            {
                "name": "transition_hidden_layers",
                "abbreviation": "thl",
                "type": "int",
                "default": 4
            },
            {
                "name": "transition_backbone",
                "description": "Backbone of Transition network.",
                "abbreviation": "tb",
                "type": "str",
                "default": "res"
            },
            {
                "name": "matcher_pretrain_epoch",
                "abbreviation": "dpe",
                "type": "int",
                "default": 0
            },
            {
                "name": "matcher_hidden_features",
                "description": "Number of neurons per layer of the matcher network.",
                "abbreviation": "dhf",
                "type": "int",
                "default": 256
            },
            {
                "name": "matcher_hidden_layers",
                "description": "Depth of the matcher network.",
                "abbreviation": "dhl",
                "type": "int",
                "default": 4
            },
            {
                "name": "g_steps",
                "description": "The number of update rounds of the generator in each epoch.",
                "type": "int",
                "default": 3
            },  
            {
                "name": "d_steps",
                "description": "Number of update rounds of matcher in each epoch.",
                "type": "int",
                "default": 1
            },
            {
                "name": "g_lr",
                "description": "Initial learning rate of the generator.",
                "type": "float",
                "default": 7e-4
            },
            {
                "name": "d_lr",
                "description": "Initial learning rate of the matcher.",
                "type": "float",
                "default": 1e-4
            },
            {
                "name": "generator_data_repeat",
                "description": "Repeat rollout more data to train generator.",
                "type": "int",
                "default": 2
            },
            {
                "name": "mae_reward_weight",
                "description": "reward = (1-mae_reward_weight)*matcher_reward + mae_reward_weight*mae_reward.",
                "type": "float",
                "default": 0.0
            }
        ],
        "revive_p": [
            {
                "name": "revive_batch_size",
                "description": "Batch size of training process.",
                "abbreviation": "mbs",
                "type": "int",
                "default": 1024
            },
            {
                "name": "revive_epoch",
                "description": "Number of epcoh for the training process",
                "abbreviation": "mep",
                "type": "int",
                "default": 1500
            },
            {
                "name": "policy_hidden_features",
                "description": "Number of neurons per layer of the policy network.",
                "abbreviation": "phf",
                "type": "int",
                "default": 256
            },
            {
                "name": "policy_hidden_layers",
                "description": "Depth of policy network.",
                "abbreviation": "phl",
                "type": "int",
                "default": 3
            },
            {
                "name": "policy_backbone",
                "description": "Backbone of policy network.",
                "abbreviation": "pb",
                "type": "str",
                "default": "mlp"
            },
            {
                "name": "transition_hidden_features",
                "description": "Number of neurons per layer of the transition network.",
                "abbreviation": "thf",
                "type": "int",
                "default": 256
            },
            {
                "name": "transition_hidden_layers",
                "abbreviation": "thl",
                "type": "int",
                "default": 4
            },
            {
                "name": "transition_backbone",
                "description": "Backbone of Transition network.",
                "abbreviation": "tb",
                "type": "str",
                "default": "res"
            },
            {
                "name": "matcher_pretrain_epoch",
                "abbreviation": "dpe",
                "type": "int",
                "default": 0
            },
            {
                "name": "matcher_hidden_features",
                "description": "Number of neurons per layer of the matcher network.",
                "abbreviation": "dhf",
                "type": "int",
                "default": 256
            },
            {
                "name": "matcher_hidden_layers",
                "description": "Depth of the matcher network.",
                "abbreviation": "dhl",
                "type": "int",
                "default": 4
            },
            {
                "name": "g_steps",
                "description": "The number of update rounds of the generator in each epoch.",
                "type": "int",
                "default": 1
            },  
            {
                "name": "d_steps",
                "description": "Number of update rounds of matcher in each epoch.",
                "type": "int",
                "default": 1
            },
            {
                "name": "g_lr",
                "description": "Initial learning rate of the generator.",
                "type": "float",
                "default": 1e-4
            },
            {
                "name": "d_lr",
                "description": "Initial learning rate of the matcher.",
                "type": "float",
                "default": 8e-4
            },
            {
                "name": "generator_data_repeat",
                "description": "Repeat rollout more data to train generator.",
                "type": "int",
                "default": 1
            }
        ]
    },
    "policy_algo_config": {
        "sac": [
            {
                "name": "ensemble_choosing_interval",
                "type": "int",
                "default": 10
            },
            {
                "name": "ensemble_size",
                "type": "int",
                "default": 50
            },
            {
                "name": "candidate_num",
                "type": "int",
                "default": 50
            },
            {
                "name": "filter",
                "type": "bool",
                "default": false
            },
            {
                "name": "policy_bc_epoch",
                "type": "int",
                "default": 500
            },
            {
                "name": "sac_batch_size",
                "description": "Batch size of training process.",
                "abbreviation": "pbs",
                "type": "int",
                "default": 1024
            },
            {
                "name" : "sac_rollout_horizon",
                "abbreviation" : "srh",
                "type" : "int",
                "default" : 100,
                "search_mode": "grid",
                "search_values": [
                    5,
                    10,
                    20
                ]
            }, 
            {
                "name": "sac_steps_per_epoch",
                "description": "The number of update rounds of sac in each epoch.",
                "abbreviation": "sspe",
                "type": "int",
                "default": 200
            },
            {
                "name": "policy_hidden_features",
                "description": "Number of neurons per layer of the policy network.",
                "abbreviation": "phf",
                "type": "int",
                "default": 256
            },
            {
                "name": "policy_hidden_layers",
                "description": "Depth of policy network.",
                "abbreviation": "phl",
                "type": "int",
                "default": 4
            },
            {
                "name": "policy_backbone",
                "description": "Backbone of policy network.",
                "abbreviation": "pb",
                "type": "str",
                "default": "mlp"
            },
            {
                "name": "buffer_size",
                "description": "Size of the buffer to store data.",
                "abbreviation": "bfs",
                "type": "int",
                "default": 1000000.0
            },
            {
                "name": "g_lr",
                "description": "Initial learning rate of the training process.",
                "type": "float",
                "default": 1e-03,
                "search_mode": "grid",
                "search_values": [
                    2e-4,
                    5e-4,
                    8e-4,
                    1e-3
                ]
            }
        ]
    }
}